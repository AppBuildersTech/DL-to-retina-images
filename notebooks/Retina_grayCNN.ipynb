{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reserve a RAM percentage for theano (cnmem = 80%)\n",
    "os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu0,lib.cnmem=0.8,nvcc.fastmath=True,floatX=float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(1337)  # for reproducibility  - (OJO: incorrect initialization can slow down or even completely stall the learning process.)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "import keras.callbacks as callbacks\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import retinaMethods as rm\n",
    "import kappa_methods as kappa\n",
    "from generators_grayPre import (BatchGenerator ,random_rotation, ValidationGenerator, OriginalDataGenerator, BatchValidationGenerator)\n",
    "import paths_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using theano\n"
     ]
    }
   ],
   "source": [
    "#Data info\n",
    "# mean_RGB = [100.009405273 ,100.227072634 , 100.786751717] #Not used \n",
    "# std_RGB = [84.3177751745 , 84.2576168412, 84.4614340298] #Not used \n",
    "\n",
    "#Network parameters\n",
    "nb_classes = 5\n",
    "# input image dimensions\n",
    "img_rows = img_cols = 512\n",
    "\n",
    "layers = 3\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3) #3×3 kernel, stride 1 and padding 1.\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (3, 3) # the pooling window is 3×3, and the stride is 2\n",
    "pool_stride = (2,2)\n",
    "\n",
    "\n",
    "#Verify if the backed of keras is Theano ('th') or TensorFlow (\"tf\") or Theano ('th'). 2016-11-17_eph_131_acc_0.49\n",
    "if K.image_dim_ordering() == 'th':\n",
    "#     X_train = X_train.reshape(X_train.shape[0], layers, img_rows, img_cols) #THE DATA IS ALREADY IN THIS FORM\n",
    "#     X_test = X_test.reshape(X_test.shape[0], layers, img_rows, img_cols)\n",
    "    input_shape = (layers, img_rows, img_cols)\n",
    "    print('Using theano')\n",
    "\n",
    "else:\n",
    "#     X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, layers)\n",
    "#     X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, layers)\n",
    "    input_shape = (img_rows, img_cols, layers)\n",
    "    print('Using tensorflow')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 512, 512)  448         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 16, 512, 512)  1024        convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 16, 512, 512)  2320        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 16, 512, 512)  1024        convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 16, 255, 255)  0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 32, 255, 255)  4640        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNormal(None, 32, 255, 255)  510         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 32, 255, 255)  9248        batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNormal(None, 32, 255, 255)  510         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 32, 127, 127)  0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 64, 127, 127)  18496       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNormal(None, 64, 127, 127)  254         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 64, 127, 127)  36928       batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNormal(None, 64, 127, 127)  254         convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 64, 63, 63)    0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 96, 63, 63)    55392       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNormal(None, 96, 63, 63)    126         convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 96, 31, 31)    0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 96, 31, 31)    83040       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNormal(None, 96, 31, 31)    62          convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 96, 15, 15)    0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 128, 15, 15)   110720      maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNormal(None, 128, 15, 15)   30          convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 128, 7, 7)     0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128, 7, 7)     0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 6272)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 96)            602208      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 96)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorma(None, 96)            192         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 5)             485         batchnormalization_10[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 927911\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we follow the convolutional layer by batch normalization layer and ReLu activations.. batch normalization????????\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(16, kernel_size[0], kernel_size[1], border_mode='same', activation='relu', input_shape=input_shape)) #,  W_regularizer=l2(0.01)))\n",
    "#Batch Normalization, 0: feature-wise normalization for the filtered images -(1: sample-wise normalization.)\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "model.add(Convolution2D(16, kernel_size[0], kernel_size[1], border_mode='same', activation='relu' )) #,  W_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size , strides=pool_stride))\n",
    "\n",
    "model.add(Convolution2D(32, kernel_size[0], kernel_size[1], border_mode='same', activation='relu'  )) #,  W_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "model.add(Convolution2D(32, kernel_size[0], kernel_size[1], border_mode='same', activation='relu' )) #, W_regularizer=l2(0.01) ))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size , strides=pool_stride))\n",
    "\n",
    "model.add(Convolution2D(64, kernel_size[0], kernel_size[1], border_mode='same', activation='relu' )) #,  W_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "model.add(Convolution2D(64, kernel_size[0], kernel_size[1], border_mode='same', activation='relu' )) #,  W_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size , strides=pool_stride))\n",
    "\n",
    "model.add(Convolution2D(96, kernel_size[0], kernel_size[1], border_mode='same', activation='relu' )) #,  W_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size , strides=pool_stride))\n",
    "\n",
    "model.add(Convolution2D(96, kernel_size[0], kernel_size[1], border_mode='same', activation='relu' )) #, W_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size , strides=pool_stride))\n",
    "\n",
    "model.add(Convolution2D(128, kernel_size[0], kernel_size[1], border_mode='same', activation='relu' ))\n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size , strides=pool_stride))\n",
    "\n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(96, activation='relu' , W_regularizer=l2(0.01))) #Relu . Saturated in cero for numbers lower tha 0\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(BatchNormalization(mode = 0)) \n",
    "model.add(Dense(nb_classes, activation='softmax' ))#,  W_regularizer=l2(0.01)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                                    #TAKER CARE!!! RUN MOUNT DATA FIRST IN CMD!!\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_string = model.to_json()\n",
    "# model = model_from_json(json_string)\n",
    "\n",
    "filepath= paths_file.json_models_path +\"Json\"+ str( datetime.now().strftime(\"%Y-%m-%d\"))+\".txt\"\n",
    "\n",
    "text_file = open(filepath, \"w\")  \n",
    "text_file.write(json_string)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's train the model using SGD + momentum (how original).\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#Loss: multiclass logloss as a loss function or Quadratic weighted kappa (QWK)\n",
    "model.compile(loss= 'categorical_crossentropy',  #kappa.quad_kappa_log_hybrid_loss_clipped, # \n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy' , kappa.quad_kappa])\n",
    "#lr = OJO: Higher learning rates will decay the loss faster, but they get stuck at worse values of loss \n",
    "print(\"Compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load Weights -------------------------------------------OJO !!!!\n",
    "\n",
    "#load Weights \n",
    "# weights = paths_file.net_weights_path  + str(\"final_2016-11-17_kappa_test_0.70.hdf5\")\n",
    "# weights = paths_file.net_weights_path  + str(\"final_2016-11-25_kappa_test_0.752.hdf5\")\n",
    "#load Weights \n",
    "# model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlotAcc(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.kappa = []\n",
    "        self.val_kappa = []\n",
    "#         print(\"logs: \",logs)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.kappa.append(logs.get('quad_kappa'))\n",
    "        self.val_kappa.append(logs.get('val_quad_kappa'))\n",
    "        \n",
    "\n",
    "\n",
    "        if(len(self.acc) > 1):\n",
    "             # summarize history for acc\n",
    "            plt.plot(self.acc)\n",
    "            plt.plot(self.val_acc)\n",
    "            plt.title('model accuracy' ) #- %d epochs'% (e+1))\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.legend(['train', 'test'], loc='upper left')\n",
    "            plt.show()\n",
    "            # summarize history for kappa\n",
    "            plt.plot(self.kappa)\n",
    "            plt.plot(self.val_kappa)\n",
    "            plt.title('Quadratic kappa' )# - %d epochs'% (e+1))\n",
    "            plt.ylabel('quad kappa')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.legend(['train', 'test'], loc='upper left')\n",
    "            plt.show()\n",
    "            # summarize history for loss\n",
    "            plt.plot(self.loss)\n",
    "            plt.plot(self.val_loss)\n",
    "            plt.title('model loss' )# - %d epochs'% (e+1))\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.legend(['train', 'test'], loc='upper left')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#TRAINING PROCESS\n",
    "print(\"Initial time: \" , datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "batch_size = 16 #16  #to fit in memory  (32 not enough memory)\n",
    "samples_per_epoch = 10000 #35100\n",
    "nb_epoch = 200\n",
    "#For validation \n",
    "batch_test = 16 \n",
    "amount_val_samples = 3000 #3000\n",
    "\n",
    "plotBehavior = PlotAcc()\n",
    "\n",
    "# checkpoint\n",
    "filepath= paths_file.net_weights_path  + str( datetime.now().strftime(\"%Y-%m-%d\"))+\"_eph_{epoch:03d}_acc_{val_acc:.2f}_val_quad_kappa_{val_quad_kappa:.2f}.hdf5\"  #\"\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "#Callbacks list\n",
    "callbacks_list = [checkpoint , plotBehavior]\n",
    "# Fit the model\n",
    "#Train uniform, val not uniform\n",
    "# history = model.fit_generator(BatchGenerator(batch_size, nb_classes) , samples_per_epoch , nb_epoch , verbose=1, callbacks=callbacks_list, validation_data= ValidationGenerator(batch_test ,nb_classes), nb_val_samples= amount_val_samples)\n",
    "#Train and val not uniform\n",
    "# history = model.fit_generator(OriginalDataGenerator(batch_size, nb_classes) , samples_per_epoch , nb_epoch , verbose=1, callbacks=callbacks_list, validation_data= ValidationGenerator(batch_size, nb_classes), nb_val_samples= amount_val_samples)\n",
    "#Train and val uniform\n",
    "history = model.fit_generator(BatchGenerator(batch_size, nb_classes) , samples_per_epoch , nb_epoch , verbose=1, \\\n",
    "                              callbacks=callbacks_list, validation_data= BatchValidationGenerator(batch_test ,nb_classes), nb_val_samples= amount_val_samples)\n",
    "\n",
    "\n",
    "#Save the history in variables\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "\n",
    "print(\"End time: \" , datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 2s     \n",
      "99/99 [==============================] - 2s\n",
      "Kappa: 0.771757918548\n"
     ]
    }
   ],
   "source": [
    "#Kappa fot a set of 100 Test IMAGES\n",
    "\n",
    "testPath = paths_file.test_processed_path\n",
    "X_test = np.load(os.path.join(testPath, \"images_200.npy\"))  \n",
    "y_test = np.load(os.path.join(testPath, \"labels_200.npy\")) \n",
    "\n",
    "for i in np.arange(X_test.shape[0]):\n",
    "    #Rotate randomly all the images\n",
    "    X_test[i] = random_rotation(X_test[i], 360, fill_mode = 'constant', cval=128)\n",
    "#Get network output\n",
    "proba = model.predict_proba(X_test)\n",
    "#print(proba)\n",
    "#Get correspongig lable to the output\n",
    "classes = model.predict_classes(X_test , batch_size= 100)\n",
    "\n",
    "k = kappa.kappa(y_test , classes , nb_classes)\n",
    "\n",
    "print(\"Kappa: \" + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0,\n",
       "       2, 2, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 3, 2, 2, 0, 0, 3, 3, 0,\n",
       "       0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Initial time: ', '2016-11-28 10:45:14')\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "99/99 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "100/100 [==============================] - 2s\n",
      "76/76 [==============================] - 1s\n",
      "('End time: ', '2016-11-28 11:13:58')\n",
      "Kappa test: 0.752653249556\n"
     ]
    }
   ],
   "source": [
    "#Kappa for all the images\n",
    "\n",
    "testPath = paths_file.test_processed_path\n",
    "\n",
    "all_imag = [f for f in os.listdir(testPath) if f.startswith('i')]\n",
    "all_label = [f for f in os.listdir(testPath) if f.startswith('l')]\n",
    "\n",
    "#Sort the files names to be according with the labeling file\n",
    "rm.sort_nicely(all_imag) \n",
    "rm.sort_nicely(all_label) \n",
    "\n",
    "pred_classes = np.array([]).astype('int')\n",
    "y_test = np.array([]).astype('int')\n",
    "\n",
    "print(\"Initial time: \" , datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "for i in xrange(len(all_imag)):\n",
    "          \n",
    "    #Read set of data\n",
    "    X_test = np.load(os.path.join(testPath, all_imag[i]))\n",
    "    \n",
    "    y_test = np.append(y_test , np.load(os.path.join(testPath, all_label[i])), axis = 0)\n",
    "    \n",
    "    #Normaliztion               \n",
    "    #Aply random rotation to the test images to make them similar to the way in wich the net was trained \n",
    "#     for i in np.arange(X_test.shape[0]):\n",
    "#         #Rotate randomly all the images\n",
    "#         X_test[i] = random_rotation(X_test[i], 360, fill_mode = 'constant', cval=128)\n",
    "    #Get correspongig lable to the output\n",
    "    pred_classes = np.append(pred_classes, model.predict_classes(X_test  , batch_size= 100), axis = 0)\n",
    "\n",
    "    del(X_test)\n",
    "            \n",
    "k = kappa.kappa(y_test , pred_classes , nb_classes)\n",
    "print(\"End time: \" , datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "print(\"Kappa test: \" + str(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PLOT any image\n",
    "array = X_test\n",
    "\n",
    "print(array.shape)\n",
    "\n",
    "array = np.rollaxis(array,1,4)\n",
    "print(array.shape)\n",
    "img = array[5,:,:,:]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Kappa fot a set of 100 Test IMAGES\n",
    "import numpy as np\n",
    "import os\n",
    "import retinaMethods as rm\n",
    "\n",
    "testPath =  paths_file.test_processed_path\n",
    "X_test = np.load(os.path.join(testPath, \"images_200.npy\"))  \n",
    "y_test = np.load(os.path.join(testPath, \"labels_200.npy\")) \n",
    "\n",
    "labelsNum = y_test\n",
    "prob = []\n",
    "print(\"Original data distribution:\")\n",
    "for k in range(5):\n",
    "    print(np.sum(labelsNum==k)/float(labelsNum.size)*100)\n",
    "    prob.append(np.sum(labelsNum==k)/float(labelsNum.size))\n",
    "    \n",
    "prob = np.array(prob)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
